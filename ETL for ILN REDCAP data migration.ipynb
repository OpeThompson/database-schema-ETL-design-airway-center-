{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "1dcf0390",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "789e92f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REDCap columns: ['record_id', 'redcap_repeat_instrument', 'redcap_repeat_instance', 'mrn', 'wakeone_mrn', 'location_ct', 'f_name', 'l_name', 'alt_name', 'dob'] ...\n",
      "Waiting sheet columns: ['ILN ID LOCATION', 'RedCAP ID', 'ENCOMPASS MRN', 'NAME', 'ALT NAME', 'ALT MRN', 'S FINDING', 'SCAD', 'S AORTA', 'High Risk/Low Risk           *NOTE:  High - current/former smoker'] ...\n",
      "Cancer sheet columns: ['Context', 'Last Name', 'First Name', 'Date of Birth ', 'MRN', 'Sex', 'ILN Detection Date', 'Nodule Size', 'Confirmed Cancer Date', 'Diagnostic Intervention'] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/opethompson/opt/anaconda3/lib/python3.9/site-packages/openpyxl/worksheet/_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "/Users/opethompson/opt/anaconda3/lib/python3.9/site-packages/openpyxl/worksheet/_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Update paths as needed\n",
    "redcap = pd.read_excel(\"/Users/opethompson/Desktop/Work - Atrium:WFBM/redcap export ILN_DATA_2025-10-06_2353 (1).xlsx\")\n",
    "waiting = pd.read_excel(\"/Users/opethompson/Desktop/Work - Atrium:WFBM/PATIENTS WAITING ON FOLLOW UP ILN.xlsx\", sheet_name=\"FOLLOW-UP >6mm\")\n",
    "cancer = pd.read_excel(\"/Users/opethompson/Desktop/Work - Atrium:WFBM/ILN CANCER DIAGNOSIS.xlsx\", sheet_name=\"LUNG CANCER DX - CUMULATIVE\")\n",
    "\n",
    "# Quick check of column names\n",
    "print(\"REDCap columns:\", redcap.columns.tolist()[:10], \"...\")\n",
    "print(\"Waiting sheet columns:\", waiting.columns.tolist()[:10], \"...\")\n",
    "print(\"Cancer sheet columns:\", cancer.columns.tolist()[:10], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e3b08235",
   "metadata": {},
   "outputs": [],
   "source": [
    "waiting_map = {\n",
    "    \"ILN ID LOCATION\": \"location_ct\",\n",
    "    \"RedCAP ID\": \"record_id\",\n",
    "    \"ENCOMPASS MRN\": \"mrn\",\n",
    "    \"NAME\": \"alt_name\",\n",
    "    \"S FINDING\": \"s_finding\",          # new variable\n",
    "    \"CT DATE\": \"date_ct\",\n",
    "    \"NODULE SIZE (mm)\": \"size\",\n",
    "    \"Nodule(s)\": \"single_mult\",\n",
    "    \"Type Nodue\": \"density\",\n",
    "    \"Nodule Location (largest)\": \"location\",\n",
    "    \"LUNG SCREEN ELIGIBLE\": \"ls_eligible\",\n",
    "    \"BRONCH DATE\": \"bronch_date\",      # new variable\n",
    "    \"IR BX DATE\": \"ir_bx_date\",        # new variable\n",
    "    \"NEW NODULE - not previously imaged\": \"new_nodule\",\n",
    "    \"Nodule 1st found\": \"date_first_found\",\n",
    "    \"PCP (Yes) or No\": \"pcp\",\n",
    "    \"PULM REF Y/N\": \"pulm_ref\",\n",
    "    \"ALREADY BEING FOLLOWED BY PULMONOLOGY\": \"already_follow\",\n",
    "    \"Discharge?\": \"dc_iln\",\n",
    "    \"DISCHARGE REASON\": \"dc_reason\",\n",
    "    \"DATE OF DEATH\": \"date_death\"\n",
    "}\n",
    "\n",
    "waiting_std = waiting.rename(columns=waiting_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "ce57da30",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_map = {\n",
    "    \"MRN\": \"mrn\",\n",
    "    \"Confirmed Cancer Date\": \"final_dx_date\",\n",
    "    \"Diagnostic Intervention\": \"final_dx_modality\",\n",
    "    \"Lung Cancer\": \"cancer_type\",\n",
    "    \"Other Cancer\": \"cancer_other\",\n",
    "    \"Stage\": \"cancer_stage\",\n",
    "    \"PRIMARY: Surg/Onc/Rad Onc\": \"treatment_1\",\n",
    "    \"Notes\": \"cancer_tnm\",\n",
    "    \"Setting of diagnosis\": \"context_dx\"\n",
    "}\n",
    "\n",
    "cancer_std = cancer.rename(columns=cancer_map)\n",
    "cancer_std[\"benign_malignant\"] = 2  # malignant = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "9e88fa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode categorical values to REDCap numeric codes\n",
    "\n",
    "# ---------- 1. Location (ILN ID LOCATION → location_ct) ----------\n",
    "location_ct_map = {\n",
    "    \"winston ed\": 1, \"winston other\": 2,\n",
    "    \"lex ed\": 3, \"lex other\": 4,\n",
    "    \"hp ed\": 5, \"hp other\": 6,\n",
    "    \"wilkes ed\": 7, \"wilkes other\": 8,\n",
    "    \"wilkes imaging\": 9,\n",
    "    \"davie all\": 10,\n",
    "    \"wfbi\": 11, \"wfbi k\": 12,\n",
    "    \"westchester\": 13,\n",
    "    \"premier\": 14\n",
    "}\n",
    "waiting_std[\"location_ct\"] = waiting_std[\"location_ct\"].astype(str).str.lower().map(location_ct_map)\n",
    "\n",
    "# ---------- 2. Nodule Location (largest) ----------\n",
    "nodule_loc_map = {\n",
    "    \"rul\": 1, \"rml\": 2, \"rll\": 3, \"lul\": 4, \"lll\": 5,\n",
    "    \"other\": 6, \"unknown\": 7\n",
    "}\n",
    "waiting_std[\"location\"] = waiting_std[\"location\"].astype(str).str.lower().map(nodule_loc_map)\n",
    "\n",
    "# ---------- 3. New Nodule ----------\n",
    "new_nodule_map = {\"yes\": 1, \"no\": 2, \"y\": 1, \"n\": 2}\n",
    "waiting_std[\"new_nodule\"] = waiting_std[\"new_nodule\"].astype(str).str.lower().map(new_nodule_map)\n",
    "\n",
    "# ---------- 4. Nodule(s) Single/Multiple ----------\n",
    "single_mult_map = {\"single\": 1, \"multiple\": 2}\n",
    "waiting_std[\"single_mult\"] = waiting_std[\"single_mult\"].astype(str).str.lower().map(single_mult_map)\n",
    "\n",
    "# ---------- 5. PCP ----------\n",
    "pcp_map = {\n",
    "    \"yes\": 1, \"y\": 1, \"true\": 1,\n",
    "    \"no\": 2, \"n\": 2, \"false\": 2,\n",
    "    \"unknown\": 3, \"\": 3, \"nan\": 3\n",
    "}\n",
    "waiting_std[\"pcp\"] = waiting_std[\"pcp\"].astype(str).str.lower().map(pcp_map)\n",
    "\n",
    "# ---------- 6. Lung Screen Eligible ----------\n",
    "ls_eligible_map = {\"yes\": 1, \"y\": 1, \"no\": 2, \"n\": 2, \"unknown\": 3}\n",
    "waiting_std[\"ls_eligible\"] = waiting_std[\"ls_eligible\"].astype(str).str.lower().map(ls_eligible_map)\n",
    "\n",
    "# ---------- 7. Pulmonology Referral ----------\n",
    "pulm_ref_map = {\"yes\": 1, \"y\": 1, \"no\": 2, \"n\": 2}\n",
    "waiting_std[\"pulm_ref\"] = waiting_std[\"pulm_ref\"].astype(str).str.lower().map(pulm_ref_map)\n",
    "\n",
    "# ---------- 8. Already being followed ----------\n",
    "already_follow_map = {\"yes\": 1, \"y\": 1, \"no\": 2, \"n\": 2}\n",
    "waiting_std[\"already_follow\"] = waiting_std[\"already_follow\"].astype(str).str.lower().map(already_follow_map)\n",
    "\n",
    "# ---------- 9. Discharge ----------\n",
    "dc_iln_map = {\"yes\": 1, \"y\": 1, \"no\": 2, \"n\": 2}\n",
    "waiting_std[\"dc_iln\"] = waiting_std[\"dc_iln\"].astype(str).str.lower().map(dc_iln_map)\n",
    "\n",
    "# ---------- 10. Discharge Reason ----------\n",
    "dc_reason_map = {\n",
    "    \"nodule stable 2+ years\": 1,\n",
    "    \"nodule resolution\": 2,\n",
    "    \"unable to contact via phone/mail\": 3,\n",
    "    \"active oncology patient\": 4,\n",
    "    \"already followed by a specialist at ahwfb\": 5,\n",
    "    \"already followed by outside facility\": 6,\n",
    "    \"care transitioned to outside facility\": 7,\n",
    "    \"on/transitioned to hospice\": 8,\n",
    "    \"patient refuses further imaging/work up\": 9,\n",
    "    \"lung screening patient\": 10,\n",
    "    \"deceased\": 11,\n",
    "    \"benign - confirmed diagnosis\": 12,\n",
    "    \"malignant - confirmed diagnosis\": 13,\n",
    "    \"not a nodule (false positive)\": 14,\n",
    "    \"other\": 15\n",
    "}\n",
    "waiting_std[\"dc_reason\"] = waiting_std[\"dc_reason\"].astype(str).str.lower().map(dc_reason_map)\n",
    "\n",
    "# ---------- 11. Density (Type Nodule) ----------\n",
    "density_map = {\"solid\": 1, \"subsolid\": 2, \"ggn\": 3, \"unsure\": 4}\n",
    "waiting_std[\"density\"] = waiting_std[\"density\"].astype(str).str.lower().map(density_map)\n",
    "\n",
    "# ---------- Diagnostic Intervention ----------\n",
    "dx_modality_map = {\n",
    "    \"BRONCHOSCOPY/BIOPSY\": 1,\n",
    "    \"CT-GUIDED TRANSTHORACIC BIOPSY\": 2,\n",
    "    \"PET/CT - TUMOR BOARD\": 3,\n",
    "    \"THORACENTESIS\": 4,\n",
    "    \"OTHER EXTRA-THORACIC BIOPSY\": 5,\n",
    "    \"PERICARDIOCENTESIS\": 6,\n",
    "    \"CRANIOTOMY\": 7,\n",
    "    \"SURGICAL RESECTION\": 8,\n",
    "    \"SERIAL IMAGING; STABLE >2YR OR RESOLVED\": 10,\n",
    "    \"OTHER\": 9\n",
    "}\n",
    "cancer_std[\"final_dx_modality\"] = cancer_std[\"final_dx_modality\"].astype(str).str.lower().map(dx_modality_map)\n",
    "\n",
    "# ---------- Lung Cancer Type ----------\n",
    "cancer_type_map = {\n",
    "    \"nsclc-adenocarcinoma\": 1, \"nsclc-squamous cell\": 2, \"squamous cell carcinoma\": 3,\n",
    "    \"adenocarcinoma in situ\": 4, \"sclc\": 5, \"sclc and nsclc\": 6, \"non small cell\": 7,\n",
    "    \"presumed lung cancer\": 8, \"neuroendocrine carcinoma of lung\": 9, \"sarcomatoid carcinoma\": 10,\n",
    "    \"carcinoid\": 11, \"poorly differentiated\": 12, \"nsclc-not otherwise specified\": 13,\n",
    "    \"NON-LUNG PRIMARY (SPECIFY)\": 14, \"unknown\": 15\n",
    "}\n",
    "cancer_std[\"cancer_type\"] = cancer_std[\"cancer_type\"].astype(str).str.lower().map(cancer_type_map)\n",
    "\n",
    "# ---------- Stage ----------\n",
    "stage_map = {\"1\": 1, \"2\": 2, \"3\": 3, \"4\": 4, \"l - sclc\": 7, \"e - sclc\": 8, \"pending\": 9, \"unknown\": 10}\n",
    "cancer_std[\"cancer_stage\"] = cancer_std[\"cancer_stage\"].astype(str).str.lower().map(stage_map)\n",
    "\n",
    "# ---------- Treatment ----------\n",
    "treatment_map = {\n",
    "    \"surgical resection\": 1, \"sbrt\": 2, \"chemotherapy\": 3, \"radiation\": 4,\n",
    "    \"chemotherapy+radiation\": 5, \"chemotherapy+immunotherapy\": 6,\n",
    "    \"immunotherapy\": 7, \"hospice care\": 8, \"pending\": 9,\n",
    "    \"med onc referral\": 10, \"refused treatment\": 11,\n",
    "    \"outside system for treatment\": 12, \"not candidate for treatment\": 13,\n",
    "    \"surgical resection-outside atrium\": 14, \"hormone therapy\": 15\n",
    "}\n",
    "cancer_std[\"treatment_1\"] = cancer_std[\"treatment_1\"].astype(str).str.lower().map(treatment_map)\n",
    "\n",
    "# ---------- Context (Setting of Diagnosis) ----------\n",
    "context_map = {\"inpatient\": 1, \"outpatient\": 2}\n",
    "cancer_std[\"context_dx\"] = cancer_std[\"context_dx\"].astype(str).str.lower().map(context_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "0d08c91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ MRN fields cleaned & standardized.\n",
      "REDCap MRNs: 992, Waiting MRNs: 2221, Cancer MRNs: 166\n",
      "\n",
      "Sample MRNs from each source:\n",
      "REDCap: ['22419425', '23195863', '22769991', '5108870', '23029669']\n",
      "Waiting: ['22419425', '23195863', '22769991', '5108870', '23029669']\n",
      "Cancer: ['3245919', '23352295', '22686058', '7204335', '18472713']\n"
     ]
    }
   ],
   "source": [
    "# --- STEP: Normalize MRNs and record IDs across all dataframes ---\n",
    "\n",
    "# --- STEP 1: Normalize column names first ---\n",
    "waiting.columns = waiting.columns.str.strip().str.lower()\n",
    "cancer.columns = cancer.columns.str.strip().str.lower()\n",
    "\n",
    "# --- STEP 2: Fix column name differences for MRN ---\n",
    "# Waiting sheet uses \"encompass mrn\"\n",
    "if \"encompass mrn\" in waiting.columns:\n",
    "    waiting[\"mrn\"] = waiting[\"encompass mrn\"]\n",
    "\n",
    "# Cancer sheet uses \"mrn\" but capitalized and possibly with spaces\n",
    "if \"mrn\" not in cancer.columns:\n",
    "    # Try to find column containing 'mrn'\n",
    "    possible_mrn = [c for c in cancer.columns if \"mrn\" in c.lower()]\n",
    "    if possible_mrn:\n",
    "        cancer[\"mrn\"] = cancer[possible_mrn[0]]\n",
    "\n",
    "# --- STEP 3: Normalize MRN format across all datasets ---\n",
    "def clean_mrn(value):\n",
    "    \"\"\"Standardize MRN-like values to string without .0 or leading zeros.\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    v = str(value).strip().lower()\n",
    "    if v.endswith(\".0\"):\n",
    "        v = v[:-2]\n",
    "    v = v.lstrip(\"0\")\n",
    "    return v\n",
    "\n",
    "# Apply cleaning\n",
    "for df in [redcap, waiting, cancer]:\n",
    "    if \"mrn\" in df.columns:\n",
    "        df[\"mrn\"] = df[\"mrn\"].apply(clean_mrn)\n",
    "    if \"record_id\" in df.columns:\n",
    "        df[\"record_id\"] = df[\"record_id\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "# --- STEP 4: Verify consistency ---\n",
    "print(\"✅ MRN fields cleaned & standardized.\")\n",
    "print(f\"REDCap MRNs: {redcap['mrn'].nunique()}, Waiting MRNs: {waiting['mrn'].nunique()}, Cancer MRNs: {cancer['mrn'].nunique()}\")\n",
    "\n",
    "# Optional sanity preview\n",
    "print(\"\\nSample MRNs from each source:\")\n",
    "print(\"REDCap:\", redcap['mrn'].dropna().astype(str).head().tolist())\n",
    "print(\"Waiting:\", waiting['mrn'].dropna().astype(str).head().tolist())\n",
    "print(\"Cancer:\", cancer['mrn'].dropna().astype(str).head().tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "d37d55f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_key_values(df):\n",
    "    \"\"\"Standardize MRN and record_id values for consistent merging.\"\"\"\n",
    "    if \"mrn\" in df.columns:\n",
    "        df[\"mrn\"] = (\n",
    "            df[\"mrn\"]\n",
    "            .astype(str)\n",
    "            .str.strip()\n",
    "            .str.replace(r\"\\.0$\", \"\", regex=True)\n",
    "            .str.lstrip(\"0\")\n",
    "            .str.lower()\n",
    "        )\n",
    "    if \"record_id\" in df.columns:\n",
    "        df[\"record_id\"] = (\n",
    "            df[\"record_id\"]\n",
    "            .astype(str)\n",
    "            .str.strip()\n",
    "            .str.replace(r\"\\.0$\", \"\", regex=True)\n",
    "            .str.lower()\n",
    "        )\n",
    "    return df\n",
    "\n",
    "# Apply to final DataFrames used in merge\n",
    "redcap = normalize_key_values(redcap)\n",
    "waiting_std = normalize_key_values(waiting_std)\n",
    "cancer_std = normalize_key_values(cancer_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "92fde8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Names normalized\n"
     ]
    }
   ],
   "source": [
    "def normalize_redcap_names(df):\n",
    "    if \"alt_name\" in df.columns:\n",
    "        def split_alt_name(name):\n",
    "            if pd.isna(name): return pd.Series([np.nan, np.nan, np.nan])\n",
    "            name = name.strip()\n",
    "            if \",\" in name:\n",
    "                last, rest = [x.strip() for x in name.split(\",\", 1)]\n",
    "                parts = rest.split()\n",
    "                first = parts[0] if parts else np.nan\n",
    "                middle = parts[1] if len(parts) > 1 else np.nan\n",
    "                return pd.Series([first, last, middle])\n",
    "            else:\n",
    "                parts = name.split()\n",
    "                return pd.Series([parts[0] if parts else np.nan, parts[-1] if len(parts)>1 else np.nan, np.nan])\n",
    "        df[[\"f_name\",\"l_name\",\"middle_name\"]] = df[\"alt_name\"].apply(split_alt_name)\n",
    "    return df\n",
    "\n",
    "def normalize_waiting_names(df):\n",
    "    if \"alt_name\" not in df.columns:\n",
    "        return df\n",
    "\n",
    "    def split_name(name):\n",
    "        if pd.isna(name):\n",
    "            return pd.Series([np.nan, np.nan])\n",
    "\n",
    "        name = str(name).strip()\n",
    "        parts = name.split()\n",
    "\n",
    "        if len(parts) == 1:\n",
    "            \n",
    "            first = parts[0]\n",
    "            last  = np.nan\n",
    "        else:\n",
    "            first = parts[0]\n",
    "            last  = parts[-1]  \n",
    "\n",
    "        return pd.Series([first, last])\n",
    "\n",
    "    df[[\"f_name\", \"l_name\"]] = df[\"alt_name\"].apply(split_name)\n",
    "    return df\n",
    "\n",
    "\n",
    "def normalize_cancer_names(df):\n",
    "    if \"last name\" in df.columns and \"first name\" in df.columns:\n",
    "        df[\"l_name\"] = df[\"last name\"].astype(str).str.strip()\n",
    "        df[\"f_name\"] = df[\"first name\"].astype(str).str.strip()\n",
    "        df[\"alt_name\"] = df[\"l_name\"] + \", \" + df[\"f_name\"]\n",
    "    return df\n",
    "\n",
    "redcap  = normalize_redcap_names(redcap)\n",
    "waiting_std = normalize_waiting_names(waiting_std)\n",
    "cancer_std  = normalize_cancer_names(cancer_std)\n",
    "\n",
    "print(\"✅ Names normalized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "31ba0095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop record_id from Excel-derived datasets so REDCap assigns new IDs\n",
    "waiting.drop(columns=[\"record_id\"], inplace=True, errors=\"ignore\")\n",
    "cancer.drop(columns=[\"record_id\"], inplace=True, errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "0cfdde32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_redcap(redcap_df, external_df, key_col=\"mrn\"):\n",
    "    \"\"\"Fill blank REDCap cells with non-null Exc# Drop record_id from Excel-derived datasets so REDCap assigns new IDs\n",
    "waiting.drop(columns=[\"record_id\"], inplace=True, errors=\"ignore\")\n",
    "cancer.drop(columns=[\"record_id\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "# Merge Waiting + Cancer\n",
    "excel_combined = pd.merge(waiting, cancer, on=\"mrn\", how=\"outer\")\n",
    "print(f\"✅ Excel merged: {excel_combined.shape}\")el data; add new MRNs as new rows.\"\"\"\n",
    "    updated = redcap_df.copy()\n",
    "\n",
    "    # --- ensure MRNs are strings ---\n",
    "    updated[key_col] = updated[key_col].astype(str)\n",
    "    external_df[key_col] = external_df[key_col].astype(str)\n",
    "\n",
    "    # --- make MRN index unique for external_df ---\n",
    "    external_df = (\n",
    "        external_df\n",
    "        .drop_duplicates(subset=[key_col], keep=\"last\")  # keep last if duplicate MRNs\n",
    "        .set_index(key_col)\n",
    "    )\n",
    "\n",
    "    # --- fill existing patients ---\n",
    "    for col in [c for c in external_df.columns if c in updated.columns]:\n",
    "        mask = updated[key_col].isin(external_df.index)\n",
    "        temp = external_df[col]\n",
    "        updated.loc[mask, col] = updated.loc[mask, col].fillna(\n",
    "            updated.loc[mask, key_col].map(temp)\n",
    "        )\n",
    "\n",
    "    # --- add new patients ---\n",
    "    redcap_keys = set(updated[key_col].dropna())\n",
    "    new_rows = external_df.loc[~external_df.index.isin(redcap_keys)].reset_index()\n",
    "    updated = pd.concat([updated, new_rows], ignore_index=True)\n",
    "\n",
    "    return updated\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b3453508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique MRNs:\n",
      "  REDCap: 993\n",
      "  Waiting: 2222\n",
      "  Cancer: 166\n",
      "\n",
      "MRN overlap with Waiting: 987\n",
      "MRN overlap with Cancer: 94\n",
      "\n",
      "Example non-matching MRNs (Excel not in REDCap):\n",
      "['23238656', '23368359', '23063588', '5124079', '4910376', '6370349', '9305928', '23436573', '8738301', '7200047']\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique MRNs:\")\n",
    "print(\"  REDCap:\", redcap[\"mrn\"].nunique())\n",
    "print(\"  Waiting:\", waiting_std[\"mrn\"].nunique())\n",
    "print(\"  Cancer:\", cancer_std[\"mrn\"].nunique())\n",
    "\n",
    "overlap_wait = len(set(redcap[\"mrn\"]) & set(waiting_std[\"mrn\"]))\n",
    "overlap_cancer = len(set(redcap[\"mrn\"]) & set(cancer_std[\"mrn\"]))\n",
    "print(f\"\\nMRN overlap with Waiting: {overlap_wait}\")\n",
    "print(f\"MRN overlap with Cancer: {overlap_cancer}\")\n",
    "\n",
    "print(\"\\nExample non-matching MRNs (Excel not in REDCap):\")\n",
    "print(list((set(waiting_std[\"mrn\"]) | set(cancer_std[\"mrn\"])) - set(redcap[\"mrn\"]))[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "95227889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Excel dataset shape: (2981, 87)\n",
      "Columns in merged Excel data: ['location_ct', 'record_id', 'mrn', 'alt_name', 'ALT NAME', 'ALT MRN', 's_finding', 'SCAD', 'S AORTA', 'High Risk/Low Risk           *NOTE:  High - current/former smoker', 'REMINDER DATE', 'date_ct', 'size', 'single_mult', 'density', 'location', 'ls_eligible', 'ZIP CODE', 'Repeat CT DATE', 'PET DATE', 'PET avid (Y/N)', 'bronch_date', 'ir_bx_date', 'CANCER DX (Y/N)', 'new_nodule', 'date_first_found', 'pcp', 'pulm_ref', 'already_follow', 'PULM REF APPT DATE', 'HEM/ONC consultation', 'LETTER SENT UNABLE TO REACH PT', 'HEALTH EQUITY NEED (non-English, uninsured, homeless, etc.-please list)', 'Previous under 6mm and grew (moved from DC to NN)', 'notes', 'Bronchoscopy biopsy', 'IR biopsy date', 'Cancer Diagnosed Y/N', 'dc_iln', 'dc_reason', 'date_death', 'Other discharge comment', 'f_name', 'l_name', 'Context', 'Last Name', 'First Name', 'Date of Birth ', 'Sex', 'ILN Detection Date', 'Nodule Size', 'final_dx_date', 'final_dx_modality', 'Other Diagnostic Intervention (comment)', 'Date Pulm Diagnostic Intervention', 'treatment_1', 'SECONDARY: Surg/Onc/Rad Onc', 'Date of Surg / Onc', 'cancer_type', 'cancer_other', 'For Data Use', 'cancer_stage', 'Smoking Status', 'cancer_tnm', 'Deceased Date:', 'Navigator ', 'LCS eligible patients', 'Notes ', 'context_dx', 'Time to Diagnosis from initial ILN enrollment', 'PYH smoking', 'Smoking Status.1', 'Years since quitting', 'Date of Birth', 'Age at ILN Detection', 'LS eligibility', 'Time of LS eligibility', 'Zip code', 'ADI - NC', 'ADI - National', 'PCP status', 'Insured/uninsured', 'Second-hand smoke exposure', 'Environmental Risk factor present', 'Family history of lung cancer', 'Optellum score', 'benign_malignant']\n",
      "✅ Dropped repeating vars: ['mrn_3', 'date_biopsy', 'bronch_date', 'ir_bx_date', 'biopsy_type', 'bx_other', 'diagnostic_nondiag']\n",
      "✅ Final cleanup complete\n",
      "✅ Assigned new record_id up to 2225\n",
      "✅ Export complete: /Users/opethompson/Desktop/Work - Atrium:WFBM/redcap_import_ready.csv\n",
      "Final REDCap import file shape: (2228, 113)\n"
     ]
    }
   ],
   "source": [
    "# --- Merge waiting + cancer datasets ---\n",
    "excel_combined = pd.merge(waiting_std, cancer_std, on=\"mrn\", how=\"outer\")\n",
    "\n",
    "print(\"Merged Excel dataset shape:\", excel_combined.shape)\n",
    "print(\"Columns in merged Excel data:\", excel_combined.columns.tolist())\n",
    "\n",
    "valid_cols = set(redcap.columns)\n",
    "excel_combined = excel_combined[excel_combined.columns.intersection(valid_cols)]\n",
    "\n",
    "\n",
    "# --- Run update ---\n",
    "final_df = update_redcap(redcap, excel_combined, \"mrn\")\n",
    "\n",
    "final_df = final_df[final_df.columns.intersection(valid_cols)]\n",
    "\n",
    "# -- cleanup category and dates ---\n",
    "\n",
    "\n",
    "# ---- LOAD REDCAP DICT + BUILD RULES ----\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dd = pd.read_csv(\"/Users/opethompson/Desktop/Work - Atrium:WFBM/IncidentalLungNodule_DataDictionary_2025-11-02.csv\")\n",
    "\n",
    "# Parse choices into dict\n",
    "def parse_choices(s):\n",
    "    \"\"\"Turn '1, Yes | 2, No' into {'1':'Yes','2':'No'}\"\"\"\n",
    "    if pd.isna(s):\n",
    "        return None\n",
    "    out = {}\n",
    "    for item in str(s).split(\"|\"):\n",
    "        item = item.strip()\n",
    "        if \",\" in item:\n",
    "            code, label = item.split(\",\", 1)\n",
    "            out[code.strip()] = label.strip()\n",
    "    return out\n",
    "\n",
    "dd[\"choices_parsed\"] = dd[\"Choices, Calculations, OR Slider Labels\"].apply(parse_choices)\n",
    "\n",
    "# Build valid category map\n",
    "valid_map = {\n",
    "    row[\"Variable / Field Name\"]: list(row[\"choices_parsed\"].keys())\n",
    "    for _, row in dd.iterrows()\n",
    "    if isinstance(row[\"choices_parsed\"], dict)\n",
    "}\n",
    "\n",
    "# ---- DROP REPEATING INSTRUMENT FIELDS ----\n",
    "\n",
    "repeat_forms = set(dd.loc[dd[\"Form Name\"].str.contains(\"biopsy\", case=False, na=False), \"Form Name\"])\n",
    "\n",
    "repeat_vars = dd.loc[\n",
    "    dd[\"Form Name\"].isin(repeat_forms), \n",
    "    \"Variable / Field Name\"\n",
    "].dropna().unique().tolist()\n",
    "\n",
    "final_df = final_df.drop(columns=[c for c in repeat_vars if c in final_df.columns], errors=\"ignore\")\n",
    "\n",
    "print(f\"✅ Dropped repeating vars: {repeat_vars}\")\n",
    "\n",
    "# ================== FINAL CLEANUP BEFORE EXPORT ==================\n",
    "\n",
    "def strip_float_strings(val):\n",
    "    \"\"\"Convert '7.0' → '7' only if integer-like.\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return np.nan\n",
    "    s = str(val).strip()\n",
    "    if s.endswith(\".0\") and s.replace(\".0\",\"\").isdigit():\n",
    "        return s.replace(\".0\",\"\")\n",
    "    return s\n",
    "\n",
    "\n",
    "# --- 1) strip .0 everywhere (safe attempt)\n",
    "for col in final_df.columns:\n",
    "    final_df[col] = final_df[col].apply(strip_float_strings)\n",
    "\n",
    "\n",
    "# --- 2) enforce categorical domain using dictionary\n",
    "for col, allowed in valid_map.items():\n",
    "    if col in final_df.columns:\n",
    "        final_df[col] = final_df[col].astype(str)\n",
    "        final_df.loc[~final_df[col].isin(allowed), col] = \"\"  \n",
    "\n",
    "\n",
    "# --- 3) checkbox fields: convert NaN→0, ensure {\"0\",\"1\"}\n",
    "checkbox_fields = [c for c in final_df.columns if \"___\" in c]\n",
    "\n",
    "for c in checkbox_fields:\n",
    "    final_df[c] = final_df[c].replace(np.nan, \"0\")\n",
    "    final_df[c] = final_df[c].astype(str).str.replace(\".0\",\"\", regex=False)\n",
    "    final_df.loc[~final_df[c].isin([\"0\",\"1\"]), c] = \"0\"\n",
    "\n",
    "\n",
    "# --- 4) completion fields\n",
    "completion_fields = [c for c in final_df.columns if c.endswith(\"_complete\")]\n",
    "\n",
    "for c in completion_fields:\n",
    "    final_df[c] = final_df[c].astype(str).str.replace(\".0\",\"\", regex=False)\n",
    "    final_df.loc[~final_df[c].isin([\"\", \"0\", \"1\", \"2\"]), c] = \"\"\n",
    "\n",
    "\n",
    "# --- 5) DATE formatting → MM/DD/YYYY\n",
    "date_cols = [c for c in final_df.columns if \"date\" in c.lower()]\n",
    "for c in date_cols:\n",
    "    final_df[c] = (\n",
    "        pd.to_datetime(final_df[c], errors=\"coerce\")\n",
    "        .dt.strftime(\"%m/%d/%Y\")\n",
    "    )\n",
    "    final_df[c] = final_df[c].replace(\"NaT\", \"\")\n",
    "    \n",
    "# === DOB FIX ===\n",
    "if \"dob\" in final_df.columns:\n",
    "    final_df[\"dob\"] = (\n",
    "        pd.to_datetime(final_df[\"dob\"], errors=\"coerce\")\n",
    "        .dt.strftime(\"%m/%d/%Y\")\n",
    "    )\n",
    "    final_df[\"dob\"] = final_df[\"dob\"].replace(\"NaT\", \"\")\n",
    "\n",
    "\n",
    "\n",
    "# --- 6) Remove literal \"nan\"\n",
    "final_df = final_df.replace(\"nan\", \"\")\n",
    "final_df = final_df.replace(np.nan, \"\")\n",
    "\n",
    "print(\"✅ Final cleanup complete\")\n",
    "\n",
    "\n",
    "# === FIX EMPTY RECORD_IDs ===\n",
    "final_df[\"record_id\"] = final_df[\"record_id\"].replace(\"\", np.nan)\n",
    "\n",
    "# Convert to numeric if possible\n",
    "existing_ids = pd.to_numeric(final_df[\"record_id\"], errors=\"coerce\")\n",
    "max_id = int(existing_ids.max())\n",
    "\n",
    "needs_id = final_df[\"record_id\"].isna()\n",
    "\n",
    "# MRN → record_id map for existing assignments\n",
    "mrn_map = (\n",
    "    final_df.loc[~needs_id, [\"mrn\", \"record_id\"]]\n",
    "    .dropna()\n",
    "    .drop_duplicates(subset=\"mrn\")\n",
    "    .set_index(\"mrn\")[\"record_id\"]\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "current = max_id\n",
    "\n",
    "for idx, row in final_df.loc[needs_id].iterrows():\n",
    "    mrn = row.get(\"mrn\", \"\")\n",
    "    \n",
    "    # Reuse existing\n",
    "    if mrn in mrn_map:\n",
    "        final_df.at[idx, \"record_id\"] = mrn_map[mrn]\n",
    "    else:\n",
    "        # Create new\n",
    "        current += 1\n",
    "        final_df.at[idx, \"record_id\"] = str(current)\n",
    "        mrn_map[mrn] = str(current)\n",
    "\n",
    "print(\"✅ Assigned new record_id up to\", current)\n",
    "\n",
    "\n",
    "# --- Export ---\n",
    "output_path = \"/Users/opethompson/Desktop/Work - Atrium:WFBM/redcap_import_ready.csv\"\n",
    "final_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Export complete: {output_path}\")\n",
    "print(\"Final REDCap import file shape:\", final_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921bdd61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
