{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "7792a766",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "60739fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REDCap columns: ['record_id', 'redcap_repeat_instrument', 'redcap_repeat_instance', 'mrn', 'wakeone_mrn', 'location_ct', 'f_name', 'l_name', 'alt_name', 'dob'] ...\n",
      "Waiting sheet columns: ['ILN ID LOCATION', 'RedCAP ID', 'ENCOMPASS MRN', 'NAME', 'ALT NAME', 'ALT MRN', 'S FINDING', 'SCAD', 'S AORTA', 'High Risk/Low Risk           *NOTE:  High - current/former smoker'] ...\n",
      "Cancer sheet columns: ['Context', 'Last Name', 'First Name', 'Date of Birth ', 'MRN', 'Sex', 'ILN Detection Date', 'Nodule Size', 'Confirmed Cancer Date', 'Diagnostic Intervention'] ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/opethompson/opt/anaconda3/lib/python3.9/site-packages/openpyxl/worksheet/_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "/Users/opethompson/opt/anaconda3/lib/python3.9/site-packages/openpyxl/worksheet/_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Update paths as needed\n",
    "redcap = pd.read_excel(\"/Users/opethompson/Desktop/Work - Atrium:WFBM/redcap export ILN_DATA_2025-10-06_2353 (1).xlsx\")\n",
    "waiting = pd.read_excel(\"/Users/opethompson/Desktop/Work - Atrium:WFBM/PATIENTS WAITING ON FOLLOW UP ILN.xlsx\", sheet_name=\"FOLLOW-UP >6mm\")\n",
    "cancer = pd.read_excel(\"/Users/opethompson/Desktop/Work - Atrium:WFBM/ILN CANCER DIAGNOSIS.xlsx\", sheet_name=\"LUNG CANCER DX - CUMULATIVE\")\n",
    "\n",
    "# Quick check of column names\n",
    "print(\"REDCap columns:\", redcap.columns.tolist()[:10], \"...\")\n",
    "print(\"Waiting sheet columns:\", waiting.columns.tolist()[:10], \"...\")\n",
    "print(\"Cancer sheet columns:\", cancer.columns.tolist()[:10], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "bfee0567",
   "metadata": {},
   "outputs": [],
   "source": [
    "waiting_map = {\n",
    "    \"ILN ID LOCATION\": \"location_ct\",\n",
    "    \"RedCAP ID\": \"record_id\",\n",
    "    \"ENCOMPASS MRN\": \"mrn\",\n",
    "    \"NAME\": \"alt_name\",\n",
    "    \"S FINDING\": \"s_finding\",          # new variable\n",
    "    \"CT DATE\": \"date_ct\",\n",
    "    \"NODULE SIZE (mm)\": \"size\",\n",
    "    \"Nodule(s)\": \"single_mult\",\n",
    "    \"Type Nodue\": \"density\",\n",
    "    \"Nodule Location (largest)\": \"location\",\n",
    "    \"LUNG SCREEN ELIGIBLE\": \"ls_eligible\",\n",
    "    \"BRONCH DATE\": \"bronch_date\",      # new variable\n",
    "    \"IR BX DATE\": \"ir_bx_date\",        # new variable\n",
    "    \"NEW NODULE - not previously imaged\": \"new_nodule\",\n",
    "    \"Nodule 1st found\": \"date_first_found\",\n",
    "    \"PCP (Yes) or No\": \"pcp\",\n",
    "    \"PULM REF Y/N\": \"pulm_ref\",\n",
    "    \"ALREADY BEING FOLLOWED BY PULMONOLOGY\": \"already_follow\",\n",
    "    \"Discharge?\": \"dc_iln\",\n",
    "    \"DISCHARGE REASON\": \"dc_reason\",\n",
    "    \"DATE OF DEATH\": \"date_death\"\n",
    "}\n",
    "\n",
    "waiting_std = waiting.rename(columns=waiting_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "f602f2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_map = {\n",
    "    \"MRN\": \"mrn\",\n",
    "    \"Confirmed Cancer Date\": \"final_dx_date\",\n",
    "    \"Diagnostic Intervention\": \"final_dx_modality\",\n",
    "    \"Lung Cancer\": \"cancer_type\",\n",
    "    \"Other Cancer\": \"cancer_other\",\n",
    "    \"Stage\": \"cancer_stage\",\n",
    "    \"PRIMARY: Surg/Onc/Rad Onc\": \"treatment_1\",\n",
    "    \"Notes\": \"cancer_tnm\",\n",
    "    \"Setting of diagnosis\": \"context_dx\"\n",
    "}\n",
    "\n",
    "cancer_std = cancer.rename(columns=cancer_map)\n",
    "cancer_std[\"benign_malignant\"] = 2  # malignant = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "b3d22c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode categorical values to REDCap numeric codes\n",
    "\n",
    "# ---------- 1. Location (ILN ID LOCATION ‚Üí location_ct) ----------\n",
    "location_ct_map = {\n",
    "    \"winston ed\": 1, \"winston other\": 2,\n",
    "    \"lex ed\": 3, \"lex other\": 4,\n",
    "    \"hp ed\": 5, \"hp other\": 6,\n",
    "    \"wilkes ed\": 7, \"wilkes other\": 8,\n",
    "    \"wilkes imaging\": 9,\n",
    "    \"davie all\": 10,\n",
    "    \"wfbi\": 11, \"wfbi k\": 12,\n",
    "    \"westchester\": 13,\n",
    "    \"premier\": 14\n",
    "}\n",
    "waiting_std[\"location_ct\"] = waiting_std[\"location_ct\"].astype(str).str.lower().map(location_ct_map)\n",
    "\n",
    "# ---------- 2. Nodule Location (largest) ----------\n",
    "nodule_loc_map = {\n",
    "    \"rul\": 1, \"rml\": 2, \"rll\": 3, \"lul\": 4, \"lll\": 5,\n",
    "    \"other\": 6, \"unknown\": 7\n",
    "}\n",
    "waiting_std[\"location\"] = waiting_std[\"location\"].astype(str).str.lower().map(nodule_loc_map)\n",
    "\n",
    "# ---------- 3. New Nodule ----------\n",
    "new_nodule_map = {\"yes\": 1, \"no\": 2, \"y\": 1, \"n\": 2}\n",
    "waiting_std[\"new_nodule\"] = waiting_std[\"new_nodule\"].astype(str).str.lower().map(new_nodule_map)\n",
    "\n",
    "# ---------- 4. Nodule(s) Single/Multiple ----------\n",
    "single_mult_map = {\"single\": 1, \"multiple\": 2}\n",
    "waiting_std[\"single_mult\"] = waiting_std[\"single_mult\"].astype(str).str.lower().map(single_mult_map)\n",
    "\n",
    "# ---------- 5. PCP ----------\n",
    "pcp_map = {\n",
    "    \"yes\": 1, \"y\": 1, \"true\": 1,\n",
    "    \"no\": 2, \"n\": 2, \"false\": 2,\n",
    "    \"unknown\": 3, \"\": 3, \"nan\": 3\n",
    "}\n",
    "waiting_std[\"pcp\"] = waiting_std[\"pcp\"].astype(str).str.lower().map(pcp_map)\n",
    "\n",
    "# ---------- 6. Lung Screen Eligible ----------\n",
    "ls_eligible_map = {\"yes\": 1, \"y\": 1, \"no\": 2, \"n\": 2, \"unknown\": 3}\n",
    "waiting_std[\"ls_eligible\"] = waiting_std[\"ls_eligible\"].astype(str).str.lower().map(ls_eligible_map)\n",
    "\n",
    "# ---------- 7. Pulmonology Referral ----------\n",
    "pulm_ref_map = {\"yes\": 1, \"y\": 1, \"no\": 2, \"n\": 2}\n",
    "waiting_std[\"pulm_ref\"] = waiting_std[\"pulm_ref\"].astype(str).str.lower().map(pulm_ref_map)\n",
    "\n",
    "# ---------- 8. Already being followed ----------\n",
    "already_follow_map = {\"yes\": 1, \"y\": 1, \"no\": 2, \"n\": 2}\n",
    "waiting_std[\"already_follow\"] = waiting_std[\"already_follow\"].astype(str).str.lower().map(already_follow_map)\n",
    "\n",
    "# ---------- 9. Discharge ----------\n",
    "dc_iln_map = {\"yes\": 1, \"y\": 1, \"no\": 2, \"n\": 2}\n",
    "waiting_std[\"dc_iln\"] = waiting_std[\"dc_iln\"].astype(str).str.lower().map(dc_iln_map)\n",
    "\n",
    "# ---------- 10. Discharge Reason ----------\n",
    "dc_reason_map = {\n",
    "    \"nodule stable 2+ years\": 1,\n",
    "    \"nodule resolution\": 2,\n",
    "    \"unable to contact via phone/mail\": 3,\n",
    "    \"active oncology patient\": 4,\n",
    "    \"already followed by a specialist at ahwfb\": 5,\n",
    "    \"already followed by outside facility\": 6,\n",
    "    \"care transitioned to outside facility\": 7,\n",
    "    \"on/transitioned to hospice\": 8,\n",
    "    \"patient refuses further imaging/work up\": 9,\n",
    "    \"lung screening patient\": 10,\n",
    "    \"deceased\": 11,\n",
    "    \"benign - confirmed diagnosis\": 12,\n",
    "    \"malignant - confirmed diagnosis\": 13,\n",
    "    \"not a nodule (false positive)\": 14,\n",
    "    \"other\": 15\n",
    "}\n",
    "waiting_std[\"dc_reason\"] = waiting_std[\"dc_reason\"].astype(str).str.lower().map(dc_reason_map)\n",
    "\n",
    "# ---------- 11. Density (Type Nodule) ----------\n",
    "density_map = {\"solid\": 1, \"subsolid\": 2, \"ggn\": 3, \"unsure\": 4}\n",
    "waiting_std[\"density\"] = waiting_std[\"density\"].astype(str).str.lower().map(density_map)\n",
    "\n",
    "# ---------- Diagnostic Intervention ----------\n",
    "dx_modality_map = {\n",
    "    \"BRONCHOSCOPY/BIOPSY\": 1,\n",
    "    \"CT-GUIDED TRANSTHORACIC BIOPSY\": 2,\n",
    "    \"PET/CT - TUMOR BOARD\": 3,\n",
    "    \"THORACENTESIS\": 4,\n",
    "    \"OTHER EXTRA-THORACIC BIOPSY\": 5,\n",
    "    \"PERICARDIOCENTESIS\": 6,\n",
    "    \"CRANIOTOMY\": 7,\n",
    "    \"SURGICAL RESECTION\": 8,\n",
    "    \"SERIAL IMAGING; STABLE >2YR OR RESOLVED\": 10,\n",
    "    \"OTHER\": 9\n",
    "}\n",
    "cancer_std[\"final_dx_modality\"] = cancer_std[\"final_dx_modality\"].astype(str).str.lower().map(dx_modality_map)\n",
    "\n",
    "# ---------- Lung Cancer Type ----------\n",
    "cancer_type_map = {\n",
    "    \"nsclc-adenocarcinoma\": 1, \"nsclc-squamous cell\": 2, \"squamous cell carcinoma\": 3,\n",
    "    \"adenocarcinoma in situ\": 4, \"sclc\": 5, \"sclc and nsclc\": 6, \"non small cell\": 7,\n",
    "    \"presumed lung cancer\": 8, \"neuroendocrine carcinoma of lung\": 9, \"sarcomatoid carcinoma\": 10,\n",
    "    \"carcinoid\": 11, \"poorly differentiated\": 12, \"nsclc-not otherwise specified\": 13,\n",
    "    \"NON-LUNG PRIMARY (SPECIFY)\": 14, \"unknown\": 15\n",
    "}\n",
    "cancer_std[\"cancer_type\"] = cancer_std[\"cancer_type\"].astype(str).str.lower().map(cancer_type_map)\n",
    "\n",
    "# ---------- Stage ----------\n",
    "stage_map = {\"1\": 1, \"2\": 2, \"3\": 3, \"4\": 4, \"l - sclc\": 7, \"e - sclc\": 8, \"pending\": 9, \"unknown\": 10}\n",
    "cancer_std[\"cancer_stage\"] = cancer_std[\"cancer_stage\"].astype(str).str.lower().map(stage_map)\n",
    "\n",
    "# ---------- Treatment ----------\n",
    "treatment_map = {\n",
    "    \"surgical resection\": 1, \"sbrt\": 2, \"chemotherapy\": 3, \"radiation\": 4,\n",
    "    \"chemotherapy+radiation\": 5, \"chemotherapy+immunotherapy\": 6,\n",
    "    \"immunotherapy\": 7, \"hospice care\": 8, \"pending\": 9,\n",
    "    \"med onc referral\": 10, \"refused treatment\": 11,\n",
    "    \"outside system for treatment\": 12, \"not candidate for treatment\": 13,\n",
    "    \"surgical resection-outside atrium\": 14, \"hormone therapy\": 15\n",
    "}\n",
    "cancer_std[\"treatment_1\"] = cancer_std[\"treatment_1\"].astype(str).str.lower().map(treatment_map)\n",
    "\n",
    "# ---------- Context (Setting of Diagnosis) ----------\n",
    "context_map = {\"inpatient\": 1, \"outpatient\": 2}\n",
    "cancer_std[\"context_dx\"] = cancer_std[\"context_dx\"].astype(str).str.lower().map(context_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "c2415a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ MRN fields cleaned & standardized.\n",
      "REDCap MRNs: 992, Waiting MRNs: 2221, Cancer MRNs: 166\n",
      "\n",
      "Sample MRNs from each source:\n",
      "REDCap: ['22419425', '23195863', '22769991', '5108870', '23029669']\n",
      "Waiting: ['22419425', '23195863', '22769991', '5108870', '23029669']\n",
      "Cancer: ['3245919', '23352295', '22686058', '7204335', '18472713']\n"
     ]
    }
   ],
   "source": [
    "# --- STEP: Normalize MRNs and record IDs across all dataframes ---\n",
    "\n",
    "# --- STEP 1: Normalize column names first ---\n",
    "waiting.columns = waiting.columns.str.strip().str.lower()\n",
    "cancer.columns = cancer.columns.str.strip().str.lower()\n",
    "\n",
    "# --- STEP 2: Fix column name differences for MRN ---\n",
    "# Waiting sheet uses \"encompass mrn\"\n",
    "if \"encompass mrn\" in waiting.columns:\n",
    "    waiting[\"mrn\"] = waiting[\"encompass mrn\"]\n",
    "\n",
    "# Cancer sheet uses \"mrn\" but capitalized and possibly with spaces\n",
    "if \"mrn\" not in cancer.columns:\n",
    "    # Try to find column containing 'mrn'\n",
    "    possible_mrn = [c for c in cancer.columns if \"mrn\" in c.lower()]\n",
    "    if possible_mrn:\n",
    "        cancer[\"mrn\"] = cancer[possible_mrn[0]]\n",
    "\n",
    "# --- STEP 3: Normalize MRN format across all datasets ---\n",
    "def clean_mrn(value):\n",
    "    \"\"\"Standardize MRN-like values to string without .0 or leading zeros.\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    v = str(value).strip().lower()\n",
    "    if v.endswith(\".0\"):\n",
    "        v = v[:-2]\n",
    "    v = v.lstrip(\"0\")\n",
    "    return v\n",
    "\n",
    "# Apply cleaning\n",
    "for df in [redcap, waiting, cancer]:\n",
    "    if \"mrn\" in df.columns:\n",
    "        df[\"mrn\"] = df[\"mrn\"].apply(clean_mrn)\n",
    "    if \"record_id\" in df.columns:\n",
    "        df[\"record_id\"] = df[\"record_id\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "# --- STEP 4: Verify consistency ---\n",
    "print(\"‚úÖ MRN fields cleaned & standardized.\")\n",
    "print(f\"REDCap MRNs: {redcap['mrn'].nunique()}, Waiting MRNs: {waiting['mrn'].nunique()}, Cancer MRNs: {cancer['mrn'].nunique()}\")\n",
    "\n",
    "# Optional sanity preview\n",
    "print(\"\\nSample MRNs from each source:\")\n",
    "print(\"REDCap:\", redcap['mrn'].dropna().astype(str).head().tolist())\n",
    "print(\"Waiting:\", waiting['mrn'].dropna().astype(str).head().tolist())\n",
    "print(\"Cancer:\", cancer['mrn'].dropna().astype(str).head().tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "178828b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_key_values(df):\n",
    "    \"\"\"Standardize MRN and record_id values for consistent merging.\"\"\"\n",
    "    if \"mrn\" in df.columns:\n",
    "        df[\"mrn\"] = (\n",
    "            df[\"mrn\"]\n",
    "            .astype(str)\n",
    "            .str.strip()\n",
    "            .str.replace(r\"\\.0$\", \"\", regex=True)\n",
    "            .str.lstrip(\"0\")\n",
    "            .str.lower()\n",
    "        )\n",
    "    if \"record_id\" in df.columns:\n",
    "        df[\"record_id\"] = (\n",
    "            df[\"record_id\"]\n",
    "            .astype(str)\n",
    "            .str.strip()\n",
    "            .str.replace(r\"\\.0$\", \"\", regex=True)\n",
    "            .str.lower()\n",
    "        )\n",
    "    return df\n",
    "\n",
    "# Apply to final DataFrames used in merge\n",
    "redcap = normalize_key_values(redcap)\n",
    "waiting_std = normalize_key_values(waiting_std)\n",
    "cancer_std = normalize_key_values(cancer_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "de42b544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Names normalized\n"
     ]
    }
   ],
   "source": [
    "def normalize_redcap_names(df):\n",
    "    if \"alt_name\" in df.columns:\n",
    "        def split_alt_name(name):\n",
    "            if pd.isna(name): return pd.Series([np.nan, np.nan, np.nan])\n",
    "            name = name.strip()\n",
    "            if \",\" in name:\n",
    "                last, rest = [x.strip() for x in name.split(\",\", 1)]\n",
    "                parts = rest.split()\n",
    "                first = parts[0] if parts else np.nan\n",
    "                middle = parts[1] if len(parts) > 1 else np.nan\n",
    "                return pd.Series([first, last, middle])\n",
    "            else:\n",
    "                parts = name.split()\n",
    "                return pd.Series([parts[0] if parts else np.nan, parts[-1] if len(parts)>1 else np.nan, np.nan])\n",
    "        df[[\"f_name\",\"l_name\",\"middle_name\"]] = df[\"alt_name\"].apply(split_alt_name)\n",
    "    return df\n",
    "\n",
    "def normalize_waiting_names(df):\n",
    "    if \"alt_name\" not in df.columns:\n",
    "        return df\n",
    "\n",
    "    def split_name(name):\n",
    "        if pd.isna(name):\n",
    "            return pd.Series([np.nan, np.nan])\n",
    "\n",
    "        name = str(name).strip()\n",
    "        parts = name.split()\n",
    "\n",
    "        if len(parts) == 1:\n",
    "            \n",
    "            first = parts[0]\n",
    "            last  = np.nan\n",
    "        else:\n",
    "            first = parts[0]\n",
    "            last  = parts[-1]  \n",
    "\n",
    "        return pd.Series([first, last])\n",
    "\n",
    "    df[[\"f_name\", \"l_name\"]] = df[\"alt_name\"].apply(split_name)\n",
    "    return df\n",
    "\n",
    "\n",
    "def normalize_cancer_names(df):\n",
    "    if \"last name\" in df.columns and \"first name\" in df.columns:\n",
    "        df[\"l_name\"] = df[\"last name\"].astype(str).str.strip()\n",
    "        df[\"f_name\"] = df[\"first name\"].astype(str).str.strip()\n",
    "        df[\"alt_name\"] = df[\"l_name\"] + \", \" + df[\"f_name\"]\n",
    "    return df\n",
    "\n",
    "redcap  = normalize_redcap_names(redcap)\n",
    "waiting_std = normalize_waiting_names(waiting_std)\n",
    "cancer_std  = normalize_cancer_names(cancer_std)\n",
    "\n",
    "print(\"‚úÖ Names normalized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "bba4ee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop record_id from Excel-derived datasets so REDCap assigns new IDs\n",
    "waiting.drop(columns=[\"record_id\"], inplace=True, errors=\"ignore\")\n",
    "cancer.drop(columns=[\"record_id\"], inplace=True, errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "32ac5a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_redcap(redcap_df, external_df, key_col=\"mrn\"):\n",
    "    \"\"\"Fill blank REDCap cells with non-null Exc# Drop record_id from Excel-derived datasets so REDCap assigns new IDs\n",
    "waiting.drop(columns=[\"record_id\"], inplace=True, errors=\"ignore\")\n",
    "cancer.drop(columns=[\"record_id\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "# Merge Waiting + Cancer\n",
    "excel_combined = pd.merge(waiting, cancer, on=\"mrn\", how=\"outer\")\n",
    "print(f\"‚úÖ Excel merged: {excel_combined.shape}\")el data; add new MRNs as new rows.\"\"\"\n",
    "    updated = redcap_df.copy()\n",
    "\n",
    "    # --- ensure MRNs are strings ---\n",
    "    updated[key_col] = updated[key_col].astype(str)\n",
    "    external_df[key_col] = external_df[key_col].astype(str)\n",
    "\n",
    "    # --- make MRN index unique for external_df ---\n",
    "    external_df = (\n",
    "        external_df\n",
    "        .drop_duplicates(subset=[key_col], keep=\"last\")  # keep last if duplicate MRNs\n",
    "        .set_index(key_col)\n",
    "    )\n",
    "\n",
    "    # --- fill existing patients ---\n",
    "    for col in [c for c in external_df.columns if c in updated.columns]:\n",
    "        mask = updated[key_col].isin(external_df.index)\n",
    "        temp = external_df[col]\n",
    "        updated.loc[mask, col] = updated.loc[mask, col].fillna(\n",
    "            updated.loc[mask, key_col].map(temp)\n",
    "        )\n",
    "\n",
    "    # --- add new patients ---\n",
    "    redcap_keys = set(updated[key_col].dropna())\n",
    "    new_rows = external_df.loc[~external_df.index.isin(redcap_keys)].reset_index()\n",
    "    updated = pd.concat([updated, new_rows], ignore_index=True)\n",
    "\n",
    "    return updated\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "54896e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique MRNs:\n",
      "  REDCap: 993\n",
      "  Waiting: 2222\n",
      "  Cancer: 166\n",
      "\n",
      "MRN overlap with Waiting: 987\n",
      "MRN overlap with Cancer: 94\n",
      "\n",
      "Example non-matching MRNs (Excel not in REDCap):\n",
      "['23238656', '23368359', '23063588', '5124079', '4910376', '6370349', '9305928', '23436573', '8738301', '7200047']\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique MRNs:\")\n",
    "print(\"  REDCap:\", redcap[\"mrn\"].nunique())\n",
    "print(\"  Waiting:\", waiting_std[\"mrn\"].nunique())\n",
    "print(\"  Cancer:\", cancer_std[\"mrn\"].nunique())\n",
    "\n",
    "overlap_wait = len(set(redcap[\"mrn\"]) & set(waiting_std[\"mrn\"]))\n",
    "overlap_cancer = len(set(redcap[\"mrn\"]) & set(cancer_std[\"mrn\"]))\n",
    "print(f\"\\nMRN overlap with Waiting: {overlap_wait}\")\n",
    "print(f\"MRN overlap with Cancer: {overlap_cancer}\")\n",
    "\n",
    "print(\"\\nExample non-matching MRNs (Excel not in REDCap):\")\n",
    "print(list((set(waiting_std[\"mrn\"]) | set(cancer_std[\"mrn\"])) - set(redcap[\"mrn\"]))[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "86797acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Excel dataset shape: (2981, 87)\n",
      "Columns in merged Excel data: ['location_ct', 'record_id', 'mrn', 'alt_name', 'ALT NAME', 'ALT MRN', 's_finding', 'SCAD', 'S AORTA', 'High Risk/Low Risk           *NOTE:  High - current/former smoker', 'REMINDER DATE', 'date_ct', 'size', 'single_mult', 'density', 'location', 'ls_eligible', 'ZIP CODE', 'Repeat CT DATE', 'PET DATE', 'PET avid (Y/N)', 'bronch_date', 'ir_bx_date', 'CANCER DX (Y/N)', 'new_nodule', 'date_first_found', 'pcp', 'pulm_ref', 'already_follow', 'PULM REF APPT DATE', 'HEM/ONC consultation', 'LETTER SENT UNABLE TO REACH PT', 'HEALTH EQUITY NEED (non-English, uninsured, homeless, etc.-please list)', 'Previous under 6mm and grew (moved from DC to NN)', 'notes', 'Bronchoscopy biopsy', 'IR biopsy date', 'Cancer Diagnosed Y/N', 'dc_iln', 'dc_reason', 'date_death', 'Other discharge comment', 'f_name', 'l_name', 'Context', 'Last Name', 'First Name', 'Date of Birth ', 'Sex', 'ILN Detection Date', 'Nodule Size', 'final_dx_date', 'final_dx_modality', 'Other Diagnostic Intervention (comment)', 'Date Pulm Diagnostic Intervention', 'treatment_1', 'SECONDARY: Surg/Onc/Rad Onc', 'Date of Surg / Onc', 'cancer_type', 'cancer_other', 'For Data Use', 'cancer_stage', 'Smoking Status', 'cancer_tnm', 'Deceased Date:', 'Navigator ', 'LCS eligible patients', 'Notes ', 'context_dx', 'Time to Diagnosis from initial ILN enrollment', 'PYH smoking', 'Smoking Status.1', 'Years since quitting', 'Date of Birth', 'Age at ILN Detection', 'LS eligibility', 'Time of LS eligibility', 'Zip code', 'ADI - NC', 'ADI - National', 'PCP status', 'Insured/uninsured', 'Second-hand smoke exposure', 'Environmental Risk factor present', 'Family history of lung cancer', 'Optellum score', 'benign_malignant']\n",
      "‚úÖ Dropped repeating vars: ['mrn_3', 'date_biopsy', 'bronch_date', 'ir_bx_date', 'biopsy_type', 'bx_other', 'diagnostic_nondiag']\n",
      "‚úÖ Final cleanup complete\n",
      "‚úÖ Assigned new record_id up to 2225\n",
      "‚úÖ Export complete: /Users/opethompson/Desktop/Work - Atrium:WFBM/redcap_import_ready.csv\n",
      "Final REDCap import file shape: (2228, 113)\n"
     ]
    }
   ],
   "source": [
    "# --- Merge waiting + cancer datasets ---\n",
    "excel_combined = pd.merge(waiting_std, cancer_std, on=\"mrn\", how=\"outer\")\n",
    "\n",
    "print(\"Merged Excel dataset shape:\", excel_combined.shape)\n",
    "print(\"Columns in merged Excel data:\", excel_combined.columns.tolist())\n",
    "\n",
    "valid_cols = set(redcap.columns)\n",
    "excel_combined = excel_combined[excel_combined.columns.intersection(valid_cols)]\n",
    "\n",
    "\n",
    "# --- Run update ---\n",
    "final_df = update_redcap(redcap, excel_combined, \"mrn\")\n",
    "\n",
    "final_df = final_df[final_df.columns.intersection(valid_cols)]\n",
    "\n",
    "# -- cleanup category and dates ---\n",
    "\n",
    "\n",
    "# ---- LOAD REDCAP DICT + BUILD RULES ----\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dd = pd.read_csv(\"/Users/opethompson/Desktop/Work - Atrium:WFBM/IncidentalLungNodule_DataDictionary_2025-11-02.csv\")\n",
    "\n",
    "# Parse choices into dict\n",
    "def parse_choices(s):\n",
    "    \"\"\"Turn '1, Yes | 2, No' into {'1':'Yes','2':'No'}\"\"\"\n",
    "    if pd.isna(s):\n",
    "        return None\n",
    "    out = {}\n",
    "    for item in str(s).split(\"|\"):\n",
    "        item = item.strip()\n",
    "        if \",\" in item:\n",
    "            code, label = item.split(\",\", 1)\n",
    "            out[code.strip()] = label.strip()\n",
    "    return out\n",
    "\n",
    "dd[\"choices_parsed\"] = dd[\"Choices, Calculations, OR Slider Labels\"].apply(parse_choices)\n",
    "\n",
    "# Build valid category map\n",
    "valid_map = {\n",
    "    row[\"Variable / Field Name\"]: list(row[\"choices_parsed\"].keys())\n",
    "    for _, row in dd.iterrows()\n",
    "    if isinstance(row[\"choices_parsed\"], dict)\n",
    "}\n",
    "\n",
    "# ---- DROP REPEATING INSTRUMENT FIELDS ----\n",
    "\n",
    "repeat_forms = set(dd.loc[dd[\"Form Name\"].str.contains(\"biopsy\", case=False, na=False), \"Form Name\"])\n",
    "\n",
    "repeat_vars = dd.loc[\n",
    "    dd[\"Form Name\"].isin(repeat_forms), \n",
    "    \"Variable / Field Name\"\n",
    "].dropna().unique().tolist()\n",
    "\n",
    "final_df = final_df.drop(columns=[c for c in repeat_vars if c in final_df.columns], errors=\"ignore\")\n",
    "\n",
    "print(f\"‚úÖ Dropped repeating vars: {repeat_vars}\")\n",
    "\n",
    "# ================== FINAL CLEANUP BEFORE EXPORT ==================\n",
    "\n",
    "def strip_float_strings(val):\n",
    "    \"\"\"Convert '7.0' ‚Üí '7' only if integer-like.\"\"\"\n",
    "    if pd.isna(val):\n",
    "        return np.nan\n",
    "    s = str(val).strip()\n",
    "    if s.endswith(\".0\") and s.replace(\".0\",\"\").isdigit():\n",
    "        return s.replace(\".0\",\"\")\n",
    "    return s\n",
    "\n",
    "\n",
    "# --- 1) strip .0 everywhere (safe attempt)\n",
    "for col in final_df.columns:\n",
    "    final_df[col] = final_df[col].apply(strip_float_strings)\n",
    "\n",
    "\n",
    "# --- 2) enforce categorical domain using dictionary\n",
    "for col, allowed in valid_map.items():\n",
    "    if col in final_df.columns:\n",
    "        final_df[col] = final_df[col].astype(str)\n",
    "        final_df.loc[~final_df[col].isin(allowed), col] = \"\"  \n",
    "\n",
    "\n",
    "# --- 3) checkbox fields: convert NaN‚Üí0, ensure {\"0\",\"1\"}\n",
    "checkbox_fields = [c for c in final_df.columns if \"___\" in c]\n",
    "\n",
    "for c in checkbox_fields:\n",
    "    final_df[c] = final_df[c].replace(np.nan, \"0\")\n",
    "    final_df[c] = final_df[c].astype(str).str.replace(\".0\",\"\", regex=False)\n",
    "    final_df.loc[~final_df[c].isin([\"0\",\"1\"]), c] = \"0\"\n",
    "\n",
    "\n",
    "# --- 4) completion fields\n",
    "completion_fields = [c for c in final_df.columns if c.endswith(\"_complete\")]\n",
    "\n",
    "for c in completion_fields:\n",
    "    final_df[c] = final_df[c].astype(str).str.replace(\".0\",\"\", regex=False)\n",
    "    final_df.loc[~final_df[c].isin([\"\", \"0\", \"1\", \"2\"]), c] = \"\"\n",
    "\n",
    "\n",
    "# --- 5) DATE formatting ‚Üí MM/DD/YYYY\n",
    "date_cols = [c for c in final_df.columns if \"date\" in c.lower()]\n",
    "for c in date_cols:\n",
    "    final_df[c] = (\n",
    "        pd.to_datetime(final_df[c], errors=\"coerce\")\n",
    "        .dt.strftime(\"%m/%d/%Y\")\n",
    "    )\n",
    "    final_df[c] = final_df[c].replace(\"NaT\", \"\")\n",
    "    \n",
    "# === DOB FIX ===\n",
    "if \"dob\" in final_df.columns:\n",
    "    final_df[\"dob\"] = (\n",
    "        pd.to_datetime(final_df[\"dob\"], errors=\"coerce\")\n",
    "        .dt.strftime(\"%m/%d/%Y\")\n",
    "    )\n",
    "    final_df[\"dob\"] = final_df[\"dob\"].replace(\"NaT\", \"\")\n",
    "\n",
    "\n",
    "\n",
    "# --- 6) Remove literal \"nan\"\n",
    "final_df = final_df.replace(\"nan\", \"\")\n",
    "final_df = final_df.replace(np.nan, \"\")\n",
    "\n",
    "print(\"‚úÖ Final cleanup complete\")\n",
    "\n",
    "\n",
    "# === FIX EMPTY RECORD_IDs ===\n",
    "final_df[\"record_id\"] = final_df[\"record_id\"].replace(\"\", np.nan)\n",
    "\n",
    "# Convert to numeric if possible\n",
    "existing_ids = pd.to_numeric(final_df[\"record_id\"], errors=\"coerce\")\n",
    "max_id = int(existing_ids.max())\n",
    "\n",
    "needs_id = final_df[\"record_id\"].isna()\n",
    "\n",
    "# MRN ‚Üí record_id map for existing assignments\n",
    "mrn_map = (\n",
    "    final_df.loc[~needs_id, [\"mrn\", \"record_id\"]]\n",
    "    .dropna()\n",
    "    .drop_duplicates(subset=\"mrn\")\n",
    "    .set_index(\"mrn\")[\"record_id\"]\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "current = max_id\n",
    "\n",
    "for idx, row in final_df.loc[needs_id].iterrows():\n",
    "    mrn = row.get(\"mrn\", \"\")\n",
    "    \n",
    "    # Reuse existing\n",
    "    if mrn in mrn_map:\n",
    "        final_df.at[idx, \"record_id\"] = mrn_map[mrn]\n",
    "    else:\n",
    "        # Create new\n",
    "        current += 1\n",
    "        final_df.at[idx, \"record_id\"] = str(current)\n",
    "        mrn_map[mrn] = str(current)\n",
    "\n",
    "print(\"‚úÖ Assigned new record_id up to\", current)\n",
    "\n",
    "\n",
    "# --- Export ---\n",
    "output_path = \"/Users/opethompson/Desktop/Work - Atrium:WFBM/redcap_import_ready.csv\"\n",
    "final_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Export complete: {output_path}\")\n",
    "print(\"Final REDCap import file shape:\", final_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "efedad6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç MERGE SUMMARY\n",
      "Existing patients in REDCap: 993\n",
      "New patients added: 1236\n",
      "Total patients after merge: 2228\n",
      "Total newly populated fields: 58859\n",
      "\n",
      "Top 10 fields newly populated:\n",
      "  - redcap_repeat_instrument: 992 updates\n",
      "  - redcap_repeat_instance: 992 updates\n",
      "  - city: 992 updates\n",
      "  - state: 992 updates\n",
      "  - insurance: 992 updates\n",
      "  - ls_eligible: 992 updates\n",
      "  - health_equity: 992 updates\n",
      "  - fhx_lung_ca: 992 updates\n",
      "  - new_nodule: 992 updates\n",
      "  - date_first_found: 992 updates\n",
      "\n",
      "üßæ Sample of new patients (first 5):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>redcap_repeat_instrument</th>\n",
       "      <th>redcap_repeat_instance</th>\n",
       "      <th>mrn</th>\n",
       "      <th>wakeone_mrn</th>\n",
       "      <th>location_ct</th>\n",
       "      <th>f_name</th>\n",
       "      <th>l_name</th>\n",
       "      <th>alt_name</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>adi_nc</th>\n",
       "      <th>adi_us</th>\n",
       "      <th>education_lvl</th>\n",
       "      <th>insurance</th>\n",
       "      <th>smoke_status</th>\n",
       "      <th>pyh</th>\n",
       "      <th>quit_date</th>\n",
       "      <th>years_quit</th>\n",
       "      <th>ls_eligible</th>\n",
       "      <th>pcp</th>\n",
       "      <th>health_equity</th>\n",
       "      <th>fhx_lung_ca</th>\n",
       "      <th>hx_cancer</th>\n",
       "      <th>hx_cancer_type</th>\n",
       "      <th>date_prior_cancer</th>\n",
       "      <th>yr_since_cancer</th>\n",
       "      <th>comorbidities___1</th>\n",
       "      <th>comorbidities___2</th>\n",
       "      <th>comorbidities___3</th>\n",
       "      <th>comorbidities___4</th>\n",
       "      <th>fvc_predpre</th>\n",
       "      <th>fev1_predpre</th>\n",
       "      <th>fvc_predpost</th>\n",
       "      <th>fev1_predpost</th>\n",
       "      <th>fev1fvcratio</th>\n",
       "      <th>dlco_pred</th>\n",
       "      <th>date_ct</th>\n",
       "      <th>demographics_and_clinical_characteristics_complete</th>\n",
       "      <th>size</th>\n",
       "      <th>single_mult</th>\n",
       "      <th>density</th>\n",
       "      <th>location</th>\n",
       "      <th>new_nodule</th>\n",
       "      <th>date_first_found</th>\n",
       "      <th>initial_size</th>\n",
       "      <th>s_finding</th>\n",
       "      <th>radiographic_characteristics_complete</th>\n",
       "      <th>repeat_ct</th>\n",
       "      <th>repeat_ct_2</th>\n",
       "      <th>repeat_ct_3</th>\n",
       "      <th>pet_ct_date</th>\n",
       "      <th>pulm_ref</th>\n",
       "      <th>pulm_date</th>\n",
       "      <th>already_follow</th>\n",
       "      <th>unable_to_reach</th>\n",
       "      <th>date_letter</th>\n",
       "      <th>referral_ls</th>\n",
       "      <th>referral_ls_prov</th>\n",
       "      <th>date_referral_ls</th>\n",
       "      <th>clinical_follow_up_complete</th>\n",
       "      <th>biopsy_complete</th>\n",
       "      <th>final_dx_date</th>\n",
       "      <th>final_dx_modality</th>\n",
       "      <th>time_to_dx</th>\n",
       "      <th>context_dx</th>\n",
       "      <th>path_report</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>benign_dx</th>\n",
       "      <th>benign_other</th>\n",
       "      <th>cancer_type</th>\n",
       "      <th>cancer_other</th>\n",
       "      <th>cancer_stage</th>\n",
       "      <th>cancer_tnm</th>\n",
       "      <th>treatment_1</th>\n",
       "      <th>treatment_2</th>\n",
       "      <th>dc_iln</th>\n",
       "      <th>dc_reason</th>\n",
       "      <th>discharge_other</th>\n",
       "      <th>date_death</th>\n",
       "      <th>final_diagnosis_and_outcomes_complete</th>\n",
       "      <th>incidental_category___1</th>\n",
       "      <th>incidental_category___2</th>\n",
       "      <th>incidental_category___3</th>\n",
       "      <th>incidental_category___4</th>\n",
       "      <th>incidental_category___5</th>\n",
       "      <th>incidental_category___6</th>\n",
       "      <th>incidental_category___7</th>\n",
       "      <th>incidental_category___8</th>\n",
       "      <th>incidental_category___9</th>\n",
       "      <th>incidental_category___10</th>\n",
       "      <th>incidental_category___11</th>\n",
       "      <th>incidental_category___12</th>\n",
       "      <th>incidental_category___13</th>\n",
       "      <th>incidental_category___14</th>\n",
       "      <th>incidental_category___15</th>\n",
       "      <th>incidental_category___16</th>\n",
       "      <th>incidental_category___17</th>\n",
       "      <th>incidental_category___18</th>\n",
       "      <th>incidental_category___19</th>\n",
       "      <th>incidental_category___20</th>\n",
       "      <th>incidental_category___21</th>\n",
       "      <th>incidental_report</th>\n",
       "      <th>cad_new_vs_known</th>\n",
       "      <th>incidental_findings_complete</th>\n",
       "      <th>middle_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [record_id, redcap_repeat_instrument, redcap_repeat_instance, mrn, wakeone_mrn, location_ct, f_name, l_name, alt_name, dob, age, sex, race, ethnicity, address, city, state, zip, adi_nc, adi_us, education_lvl, insurance, smoke_status, pyh, quit_date, years_quit, ls_eligible, pcp, health_equity, fhx_lung_ca, hx_cancer, hx_cancer_type, date_prior_cancer, yr_since_cancer, comorbidities___1, comorbidities___2, comorbidities___3, comorbidities___4, fvc_predpre, fev1_predpre, fvc_predpost, fev1_predpost, fev1fvcratio, dlco_pred, date_ct, demographics_and_clinical_characteristics_complete, size, single_mult, density, location, new_nodule, date_first_found, initial_size, s_finding, radiographic_characteristics_complete, repeat_ct, repeat_ct_2, repeat_ct_3, pet_ct_date, pulm_ref, pulm_date, already_follow, unable_to_reach, date_letter, referral_ls, referral_ls_prov, date_referral_ls, clinical_follow_up_complete, biopsy_complete, final_dx_date, final_dx_modality, time_to_dx, context_dx, path_report, benign_malignant, benign_dx, benign_other, cancer_type, cancer_other, cancer_stage, cancer_tnm, treatment_1, treatment_2, dc_iln, dc_reason, discharge_other, date_death, final_diagnosis_and_outcomes_complete, incidental_category___1, incidental_category___2, incidental_category___3, incidental_category___4, incidental_category___5, incidental_category___6, incidental_category___7, incidental_category___8, incidental_category___9, incidental_category___10, incidental_category___11, incidental_category___12, ...]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üßæ Sample of updated existing patients (first 5):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>redcap_repeat_instrument</th>\n",
       "      <th>redcap_repeat_instance</th>\n",
       "      <th>mrn</th>\n",
       "      <th>wakeone_mrn</th>\n",
       "      <th>location_ct</th>\n",
       "      <th>f_name</th>\n",
       "      <th>l_name</th>\n",
       "      <th>alt_name</th>\n",
       "      <th>dob</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>adi_nc</th>\n",
       "      <th>adi_us</th>\n",
       "      <th>education_lvl</th>\n",
       "      <th>insurance</th>\n",
       "      <th>smoke_status</th>\n",
       "      <th>pyh</th>\n",
       "      <th>quit_date</th>\n",
       "      <th>years_quit</th>\n",
       "      <th>ls_eligible</th>\n",
       "      <th>pcp</th>\n",
       "      <th>health_equity</th>\n",
       "      <th>fhx_lung_ca</th>\n",
       "      <th>hx_cancer</th>\n",
       "      <th>hx_cancer_type</th>\n",
       "      <th>date_prior_cancer</th>\n",
       "      <th>yr_since_cancer</th>\n",
       "      <th>comorbidities___1</th>\n",
       "      <th>comorbidities___2</th>\n",
       "      <th>comorbidities___3</th>\n",
       "      <th>comorbidities___4</th>\n",
       "      <th>fvc_predpre</th>\n",
       "      <th>fev1_predpre</th>\n",
       "      <th>fvc_predpost</th>\n",
       "      <th>fev1_predpost</th>\n",
       "      <th>fev1fvcratio</th>\n",
       "      <th>dlco_pred</th>\n",
       "      <th>date_ct</th>\n",
       "      <th>demographics_and_clinical_characteristics_complete</th>\n",
       "      <th>size</th>\n",
       "      <th>single_mult</th>\n",
       "      <th>density</th>\n",
       "      <th>location</th>\n",
       "      <th>new_nodule</th>\n",
       "      <th>date_first_found</th>\n",
       "      <th>initial_size</th>\n",
       "      <th>s_finding</th>\n",
       "      <th>radiographic_characteristics_complete</th>\n",
       "      <th>repeat_ct</th>\n",
       "      <th>repeat_ct_2</th>\n",
       "      <th>repeat_ct_3</th>\n",
       "      <th>pet_ct_date</th>\n",
       "      <th>pulm_ref</th>\n",
       "      <th>pulm_date</th>\n",
       "      <th>already_follow</th>\n",
       "      <th>unable_to_reach</th>\n",
       "      <th>date_letter</th>\n",
       "      <th>referral_ls</th>\n",
       "      <th>referral_ls_prov</th>\n",
       "      <th>date_referral_ls</th>\n",
       "      <th>clinical_follow_up_complete</th>\n",
       "      <th>biopsy_complete</th>\n",
       "      <th>final_dx_date</th>\n",
       "      <th>final_dx_modality</th>\n",
       "      <th>time_to_dx</th>\n",
       "      <th>context_dx</th>\n",
       "      <th>path_report</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>benign_dx</th>\n",
       "      <th>benign_other</th>\n",
       "      <th>cancer_type</th>\n",
       "      <th>cancer_other</th>\n",
       "      <th>cancer_stage</th>\n",
       "      <th>cancer_tnm</th>\n",
       "      <th>treatment_1</th>\n",
       "      <th>treatment_2</th>\n",
       "      <th>dc_iln</th>\n",
       "      <th>dc_reason</th>\n",
       "      <th>discharge_other</th>\n",
       "      <th>date_death</th>\n",
       "      <th>final_diagnosis_and_outcomes_complete</th>\n",
       "      <th>incidental_category___1</th>\n",
       "      <th>incidental_category___2</th>\n",
       "      <th>incidental_category___3</th>\n",
       "      <th>incidental_category___4</th>\n",
       "      <th>incidental_category___5</th>\n",
       "      <th>incidental_category___6</th>\n",
       "      <th>incidental_category___7</th>\n",
       "      <th>incidental_category___8</th>\n",
       "      <th>incidental_category___9</th>\n",
       "      <th>incidental_category___10</th>\n",
       "      <th>incidental_category___11</th>\n",
       "      <th>incidental_category___12</th>\n",
       "      <th>incidental_category___13</th>\n",
       "      <th>incidental_category___14</th>\n",
       "      <th>incidental_category___15</th>\n",
       "      <th>incidental_category___16</th>\n",
       "      <th>incidental_category___17</th>\n",
       "      <th>incidental_category___18</th>\n",
       "      <th>incidental_category___19</th>\n",
       "      <th>incidental_category___20</th>\n",
       "      <th>incidental_category___21</th>\n",
       "      <th>incidental_report</th>\n",
       "      <th>cad_new_vs_known</th>\n",
       "      <th>incidental_findings_complete</th>\n",
       "      <th>middle_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>22419425</td>\n",
       "      <td>22419425</td>\n",
       "      <td>1</td>\n",
       "      <td>DAVID</td>\n",
       "      <td>COOK</td>\n",
       "      <td>COOK,DAVID WILLIAM</td>\n",
       "      <td>12/13/1951</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2220 EULA RD</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>27018-7818</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>01/08/2000</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>04/12/2024</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>04/12/2024</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>WILLIAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>23195863</td>\n",
       "      <td>23195863</td>\n",
       "      <td>1</td>\n",
       "      <td>CAROLYN</td>\n",
       "      <td>POPE</td>\n",
       "      <td>POPE,CAROLYN MCCULLOUGH</td>\n",
       "      <td>10/09/1931</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>318 WREN BLVD</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>27292</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>04/17/2024</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>05/09/2016</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>MCCULLOUGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>22769991</td>\n",
       "      <td>22769991</td>\n",
       "      <td>1</td>\n",
       "      <td>BARBARA</td>\n",
       "      <td>SMITH</td>\n",
       "      <td>SMITH,BARBARA LEE</td>\n",
       "      <td>02/01/1937</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2916 LAKAWANNA DR</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>27051-9614</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>04/24/2024</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>09/02/2022</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>LEE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>5108870</td>\n",
       "      <td>5108870</td>\n",
       "      <td>1</td>\n",
       "      <td>NATHALIA</td>\n",
       "      <td>ALLEN</td>\n",
       "      <td>ALLEN,NATHALIA LATRIVA</td>\n",
       "      <td>09/08/1971</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>801 N Martin Luther King Jr Drive Apt R</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>27101</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87.1</td>\n",
       "      <td>85.7</td>\n",
       "      <td>78.1</td>\n",
       "      <td>84.5</td>\n",
       "      <td>80</td>\n",
       "      <td>66.3</td>\n",
       "      <td>04/07/2024</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>10/25/2019</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>LATRIVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>23029669</td>\n",
       "      <td>23029669</td>\n",
       "      <td>1</td>\n",
       "      <td>DARLENE</td>\n",
       "      <td>JOHNSON</td>\n",
       "      <td>JOHNSON,DARLENE</td>\n",
       "      <td>03/14/1958</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>125 FERRELL HEIGHTS COURT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>27101</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>04/10/2024</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  record_id redcap_repeat_instrument redcap_repeat_instance       mrn wakeone_mrn location_ct    f_name   l_name                 alt_name  \\\n",
       "0         1                                                  22419425    22419425           1     DAVID     COOK       COOK,DAVID WILLIAM   \n",
       "1         2                                                  23195863    23195863           1   CAROLYN     POPE  POPE,CAROLYN MCCULLOUGH   \n",
       "2         3                                                  22769991    22769991           1   BARBARA    SMITH        SMITH,BARBARA LEE   \n",
       "3         4                                                   5108870     5108870           1  NATHALIA    ALLEN   ALLEN,NATHALIA LATRIVA   \n",
       "4         5                                                  23029669    23029669           1   DARLENE  JOHNSON          JOHNSON,DARLENE   \n",
       "\n",
       "          dob age sex race ethnicity                                  address city state         zip adi_nc adi_us education_lvl insurance  \\\n",
       "0  12/13/1951       2    1         1                             2220 EULA RD             27018-7818                                         \n",
       "1  10/09/1931       1    1         1                            318 WREN BLVD                  27292                                         \n",
       "2  02/01/1937       1    1         1                        2916 LAKAWANNA DR             27051-9614                                         \n",
       "3  09/08/1971       1    2         1  801 N Martin Luther King Jr Drive Apt R                  27101                                         \n",
       "4  03/14/1958       1    2         1                125 FERRELL HEIGHTS COURT                  27101                                         \n",
       "\n",
       "  smoke_status pyh   quit_date years_quit ls_eligible pcp health_equity fhx_lung_ca hx_cancer hx_cancer_type date_prior_cancer yr_since_cancer  \\\n",
       "0            2   0  01/08/2000                          1                                   1                                                    \n",
       "1            3                                          1                                   2                                                    \n",
       "2            3                                          1                                   2                                                    \n",
       "3            1                                          1                                   2                                                    \n",
       "4            1                                          1                                   2                                                    \n",
       "\n",
       "  comorbidities___1 comorbidities___2 comorbidities___3 comorbidities___4 fvc_predpre fev1_predpre fvc_predpost fev1_predpost fev1fvcratio  \\\n",
       "0                 0                 0                 0                 0                                                                    \n",
       "1                 0                 0                 0                 0                                                                    \n",
       "2                 0                 0                 0                 0                                                                    \n",
       "3                 0                 0                 0                 0        87.1         85.7         78.1          84.5           80   \n",
       "4                 0                 0                 0                 0                                                                    \n",
       "\n",
       "  dlco_pred     date_ct demographics_and_clinical_characteristics_complete size single_mult density location new_nodule date_first_found  \\\n",
       "0            04/12/2024                                                  0    7           1       1        3                  04/12/2024   \n",
       "1            04/17/2024                                                  0   10           2       1        1                  05/09/2016   \n",
       "2            04/24/2024                                                  0    6           2       1        6                  09/02/2022   \n",
       "3      66.3  04/07/2024                                                  0    6           1       1        1                  10/25/2019   \n",
       "4            04/10/2024                                                  0   10           2       1        1                               \n",
       "\n",
       "  initial_size s_finding radiographic_characteristics_complete repeat_ct repeat_ct_2 repeat_ct_3 pet_ct_date pulm_ref pulm_date already_follow  \\\n",
       "0                                                            0                                                      2                            \n",
       "1                                                            0                                                      1                            \n",
       "2                                                            0                                                                                   \n",
       "3                                                            0                                                      1                            \n",
       "4                                                            0                                                      1                            \n",
       "\n",
       "  unable_to_reach date_letter referral_ls referral_ls_prov date_referral_ls clinical_follow_up_complete biopsy_complete final_dx_date  \\\n",
       "0                                                                                                                                       \n",
       "1                                                                                                                                       \n",
       "2                                                                                                                                       \n",
       "3                                                                                                                                       \n",
       "4                                                                                                                                       \n",
       "\n",
       "  final_dx_modality time_to_dx context_dx path_report benign_malignant benign_dx benign_other cancer_type cancer_other cancer_stage cancer_tnm  \\\n",
       "0                                                                                                                                                \n",
       "1                                                                                                                                                \n",
       "2                                                                                                                                                \n",
       "3                                                                                                                                                \n",
       "4                                                                                                                                                \n",
       "\n",
       "  treatment_1 treatment_2 dc_iln dc_reason discharge_other date_death final_diagnosis_and_outcomes_complete incidental_category___1  \\\n",
       "0                              1         4                                                                0                       0   \n",
       "1                              1         9                                                                0                       0   \n",
       "2                              1        11                                                                0                       0   \n",
       "3                              1         1                                                                0                       0   \n",
       "4                              1        14                                                                0                       0   \n",
       "\n",
       "  incidental_category___2 incidental_category___3 incidental_category___4 incidental_category___5 incidental_category___6 incidental_category___7  \\\n",
       "0                       0                       0                       0                       0                       0                       0   \n",
       "1                       0                       0                       0                       0                       0                       0   \n",
       "2                       0                       0                       0                       0                       0                       0   \n",
       "3                       0                       0                       0                       0                       0                       0   \n",
       "4                       0                       0                       0                       0                       0                       0   \n",
       "\n",
       "  incidental_category___8 incidental_category___9 incidental_category___10 incidental_category___11 incidental_category___12  \\\n",
       "0                       0                       0                        0                        0                        0   \n",
       "1                       0                       0                        0                        0                        0   \n",
       "2                       0                       0                        0                        0                        0   \n",
       "3                       0                       0                        0                        0                        0   \n",
       "4                       0                       0                        0                        0                        0   \n",
       "\n",
       "  incidental_category___13 incidental_category___14 incidental_category___15 incidental_category___16 incidental_category___17  \\\n",
       "0                        0                        0                        0                        0                        0   \n",
       "1                        0                        0                        0                        0                        0   \n",
       "2                        0                        0                        0                        0                        0   \n",
       "3                        0                        0                        0                        0                        0   \n",
       "4                        0                        0                        0                        0                        0   \n",
       "\n",
       "  incidental_category___18 incidental_category___19 incidental_category___20 incidental_category___21 incidental_report cad_new_vs_known  \\\n",
       "0                        0                        0                        0                        0                                      \n",
       "1                        0                        0                        0                        0                                      \n",
       "2                        0                        0                        0                        0                                      \n",
       "3                        0                        0                        0                        0                                      \n",
       "4                        0                        0                        0                        0                                      \n",
       "\n",
       "  incidental_findings_complete middle_name  \n",
       "0                            0     WILLIAM  \n",
       "1                            0  MCCULLOUGH  \n",
       "2                            0         LEE  \n",
       "3                            0     LATRIVA  \n",
       "4                            0              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- STEP 6: Diagnostic Summary Preview ---\n",
    "\n",
    "def summarize_updates(original_df, updated_df, key_cols=[\"mrn\", \"record_id\"]):\n",
    "    \"\"\"\n",
    "    Summarize updates between original and updated REDCap dataframes.\n",
    "    Shows counts of:\n",
    "      - Existing records updated\n",
    "      - New patients added\n",
    "      - Variables newly populated\n",
    "    \"\"\"\n",
    "    summary = {}\n",
    "    \n",
    "    # Normalize keys\n",
    "    for k in key_cols:\n",
    "        original_df[k] = original_df[k].astype(str).str.lower().str.strip()\n",
    "        updated_df[k] = updated_df[k].astype(str).str.lower().str.strip()\n",
    "\n",
    "    # --- Identify new vs existing ---\n",
    "    orig_keys = set(original_df[key_cols].apply(tuple, axis=1))\n",
    "    new_keys = set(updated_df[key_cols].apply(tuple, axis=1))\n",
    "    added_keys = new_keys - orig_keys\n",
    "    common_keys = new_keys & orig_keys\n",
    "\n",
    "    summary[\"existing_patients_in_redcap\"] = len(orig_keys)\n",
    "    summary[\"new_patients_added\"] = len(added_keys)\n",
    "    summary[\"total_patients_after_merge\"] = len(new_keys)\n",
    "\n",
    "    # --- Detect updated fields for existing patients ---\n",
    "    changed_count = 0\n",
    "    changed_cols = {}\n",
    "\n",
    "    for key in common_keys:\n",
    "        orig_row = original_df.loc[\n",
    "            (original_df[key_cols].apply(tuple, axis=1) == key)\n",
    "        ].squeeze()\n",
    "        new_row = updated_df.loc[\n",
    "            (updated_df[key_cols].apply(tuple, axis=1) == key)\n",
    "        ].squeeze()\n",
    "\n",
    "        # Compare columns\n",
    "        for col in updated_df.columns:\n",
    "            if col in key_cols or col not in original_df.columns:\n",
    "                continue\n",
    "            val_orig = orig_row.get(col, np.nan)\n",
    "            val_new = new_row.get(col, np.nan)\n",
    "            if pd.isna(val_orig) and pd.notna(val_new):\n",
    "                changed_count += 1\n",
    "                changed_cols[col] = changed_cols.get(col, 0) + 1\n",
    "\n",
    "    summary[\"existing_patients_updated\"] = len(common_keys)\n",
    "    summary[\"fields_newly_populated\"] = changed_count\n",
    "    summary[\"top_fields_updated\"] = sorted(\n",
    "        changed_cols.items(), key=lambda x: x[1], reverse=True\n",
    "    )[:10]\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "# --- Run summary ---\n",
    "summary = summarize_updates(redcap, final_df)\n",
    "print(\"üîç MERGE SUMMARY\")\n",
    "print(f\"Existing patients in REDCap: {summary['existing_patients_in_redcap']}\")\n",
    "print(f\"New patients added: {summary['new_patients_added']}\")\n",
    "print(f\"Total patients after merge: {summary['total_patients_after_merge']}\")\n",
    "print(f\"Total newly populated fields: {summary['fields_newly_populated']}\")\n",
    "print(\"\\nTop 10 fields newly populated:\")\n",
    "for field, count in summary[\"top_fields_updated\"]:\n",
    "    print(f\"  - {field}: {count} updates\")\n",
    "\n",
    "# --- Quick sanity preview ---\n",
    "print(\"\\nüßæ Sample of new patients (first 5):\")\n",
    "display(final_df[final_df[\"record_id\"].isna()].head())\n",
    "\n",
    "print(\"\\nüßæ Sample of updated existing patients (first 5):\")\n",
    "display(final_df[final_df[\"record_id\"].notna()].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df21cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
